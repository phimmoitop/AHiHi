name: AHiHi to CF (AI Anime Master)

on:
  workflow_dispatch:
    inputs:
      type: { description: "Type", required: true }
      slug: { description: "Slug", required: true }
      ss: { description: "Season", required: true }
      ep: { description: "Ep", required: true }
      hid: { description: "Hid", required: true }
      token: { description: 'Token', required: true }
      page: { description: 'Page', required: true }
      account: { description: 'AID', required: true }
      key: { description: 'Key', required: true }

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Environment
        run: |
          sudo apt update
          sudo apt install -y ffmpeg curl jq python3 python3-pip
          pip3 install edge-tts webvtt-py google-generativeai

      - name: Get download and subtitle link
        id: getlink
        run: |
          HID="${{ github.event.inputs.hid }}"
          EP="${{ github.event.inputs.ep }}"
          RESP1=$(curl -s "https://hihianimeapi.onrender.com/api/v1/episodes/a-${HID}")
          LINK_EP=$(echo "$RESP1" | jq -r ".data[] | select(.episodeNumber == ($EP|tonumber)) | .id")
          RESP2=$(curl -s "https://hihianimeapi.onrender.com/api/v1/stream?type=sub&server=hd-2&id=${LINK_EP}")
          LINK_DL=$(echo "$RESP2" | jq -r '.data.link.file')
          LINK_SUB=$(echo "$RESP2" | jq -r '.data.tracks[]? | select(.label == "English") | .file' | head -n 1)
          if [ -z "$LINK_SUB" ] || [ "$LINK_SUB" == "null" ]; then
            LINK_SUB=$(echo "$RESP2" | jq -r '.data.tracks[0].file')
          fi
          echo "LINK_DL=$LINK_DL" >> $GITHUB_ENV
          echo "LINK_SUB=$LINK_SUB" >> $GITHUB_ENV

      - name: Download video and subtitle
        run: |
          ffmpeg -i "$LINK_DL" -c copy -bsf:a aac_adtstoasc "raw_video.mp4"
          curl -L "$LINK_SUB" -o "eng.vtt"

      - name: AI Contextual Translation & TTS
        env:
          GEMINI_API_KEY: ${{ github.event.inputs.key }}
        run: |
          python3 <<EOF
          import webvtt
          import google.generativeai as genai
          import os, asyncio, edge_tts, time

          genai.configure(api_key=os.environ['GEMINI_API_KEY'])
          model = genai.GenerativeModel('gemini-1.5-flash')

          async def process():
              vtt = webvtt.read('eng.vtt')
              total = len(vtt)
              if not os.path.exists('chunks'): os.makedirs('chunks')

              batch_size = 25
              all_translated_texts = []

              print(f"ðŸš€ AI Gemini Ä‘ang dá»‹ch thuáº­t phong cÃ¡ch Anime Fantasy...")

              for i in range(0, total, batch_size):
                  batch = vtt[i:i+batch_size]
                  en_text = "\n".join([f"{idx+i}: {cap.text}" for idx, cap in enumerate(batch)])
                  
                  prompt = f"""
                  Dá»‹ch Ä‘oáº¡n há»™i thoáº¡i Anime sau sang tiáº¿ng Viá»‡t:
                  1. VÄƒn phong: Anime Fantasy cá»• Ä‘áº¡i (VÆ°Æ¡ng quá»‘c, Ma VÆ°Æ¡ng, ThÆ°á»£ng Äáº¿).
                  2. NhÃ¢n xÆ°ng: DÃ¹ng 'Ta - NgÆ°Æ¡i' cho Ä‘á»‘i Ä‘áº§u/trang trá»ng, 'Anh - Em' hoáº·c 'Tá»› - Cáº­u' cho thÃ¢n thiáº¿t.
                  3. TÃªn riÃªng & Äá»‹a danh: GIá»® NGUYÃŠN tÃªn gá»‘c (vÃ­ dá»¥: Naruto, Liones, Britannia) vÃ  viáº¿t hoa.
                  4. Tá»« quan trá»ng: Ma VÆ°Æ¡ng, Tháº§n, VÆ°Æ¡ng Quá»‘c, ThÃ¡nh Kiáº¿m... PHáº¢I viáº¿t hoa.
                  5. Äá»‹nh dáº¡ng: Tráº£ vá» tá»«ng cÃ¢u theo sá»‘ thá»© tá»± 'ID: Ná»™i dung'. KhÃ´ng giáº£i thÃ­ch.
                  
                  {en_text}
                  """
                  try:
                      response = model.generate_content(prompt)
                      lines = response.text.strip().split('\n')
                      for line in lines:
                          if ': ' in line: all_translated_texts.append(line.split(': ', 1)[1])
                          else: all_translated_texts.append(line)
                  except:
                      all_translated_texts.extend(["..."] * len(batch))
                  
                  print(f"Tiáº¿n Ä‘á»™: {min(i+batch_size, total)}/{total}")
                  time.sleep(1)

              vi_vtt = webvtt.WebVTT()
              for i, caption in enumerate(vtt):
                  text_vi = all_translated_texts[i] if i < len(all_translated_texts) else "..."
                  vi_vtt.captions.append(webvtt.Caption(caption.start, caption.end, text_vi))
                  # Táº¡o TTS
                  communicate = edge_tts.Communicate(text_vi, "vi-VN-HoaiMyNeural")
                  await communicate.save(f"chunks/c_{i}.mp3")
              
              vi_vtt.save('vi.vtt')

          asyncio.run(process())
          EOF

      - name: Build Unified Filter Script
        run: |
          python3 <<EOF
          import webvtt
          vtt = webvtt.read('vi.vtt')
          
          with open('master_filter.txt', 'w') as f:
              # 1. TrÃ¬ hoÃ£n tá»«ng cÃ¢u audio (adelay)
              for i, cap in enumerate(vtt):
                  h, m, s = cap.start.replace(',', '.').split(':')
                  ms = int(float(h)*3600000 + float(m)*60000 + float(s)*1000)
                  f.write(f"[{i+1}:a]adelay={ms}|{ms}[a{i}];")
              
              # 2. Mix cÃ¡c cÃ¢u audio TTS láº¡i thÃ nh má»™t dÃ²ng
              labels = "".join([f"[a{i}]" for i in range(len(vtt))])
              f.write(f"{labels}amix=inputs={len(vtt)}:dropout_transition=0,volume=3.5[tts_only];")
              
              # 3. Mix nháº¡c ná»n video (0.6) vá»›i audio thuyáº¿t minh (tts_only)
              f.write(f"[0:a]volume=0.6[bg_music];[bg_music][tts_only]amix=inputs=2:duration=first[out_audio];")
              
              # 4. Add Sub cá»©ng vÃ o video
              f.write(f"[0:v]subtitles=vi.vtt:force_style='FontSize=20,PrimaryColour=&H00FFFF&,Outline=1,Shadow=1'[out_video]")
          EOF

      - name: Final Render (Fixed 5s Segment)
        run: |
          NAME="${{ github.event.inputs.type }}-${{ github.event.inputs.slug }}-${{ github.event.inputs.ss }}-${{ github.event.inputs.ep }}"
          
          # Gom Inputs: Video (0) + Chunks MP3 (1...N)
          INPUTS="-i raw_video.mp4"
          for f in $(ls -v chunks/c_*.mp3); do INPUTS="$INPUTS -i $f"; done

          # Render sá»­ dá»¥ng filter_complex_script Ä‘Ã£ gá»™p toÃ n bá»™
          ffmpeg -y $INPUTS -filter_complex_script master_filter.txt \
            -map "[out_video]" -map "[out_audio]" \
            -c:v libx264 -preset superfast -crf 22 \
            -g 120 -keyint_min 120 -sc_threshold 0 \
            -c:a aac -b:a 128k "final_video.mp4"

          # TÃ¡ch HLS 5s segment (.png)
          mkdir -p output
          ffmpeg -i final_video.mp4 -c copy -f hls -hls_time 5 \
            -hls_segment_type fmp4 -hls_fmp4_init_filename "${NAME}-index.png" \
            -hls_segment_filename "output/${NAME}-index%d.png" "output/${NAME}.m3u8"
          cp vi.vtt output/

      - name: Deploy to Cloudflare Pages
        uses: cloudflare/pages-action@v1
        with:
          apiToken: ${{ github.event.inputs.token }}
          accountId: ${{ github.event.inputs.account }}
          projectName: ${{ github.event.inputs.page }}
          directory: ./output
          branch: ${{ github.event.inputs.type }}-${{ github.event.inputs.slug }}-${{ github.event.inputs.ss }}-${{ github.event.inputs.ep }}
