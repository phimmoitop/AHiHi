name: AHiHi to CF (AI Anime Master)

on:
  workflow_dispatch:
    inputs:
      type: { description: "Type", required: true }
      slug: { description: "Slug", required: true }
      ss: { description: "Season", required: true }
      ep: { description: "Ep", required: true }
      hid: { description: "Hid", required: true }
      token: { description: 'Token', required: true }
      page: { description: 'Page', required: true }
      account: { description: 'AID', required: true }
      key: { description: 'Gemini API Key', required: true }

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Environment
        run: |
          sudo apt update
          sudo apt install -y ffmpeg curl jq python3 python3-pip
          # CÃ i Ä‘áº·t thÆ° viá»‡n AI tháº¿ há»‡ má»›i
          pip3 install edge-tts webvtt-py google-genai

      - name: Get download and subtitle link
        id: getlink
        run: |
          HID="${{ github.event.inputs.hid }}"
          EP="${{ github.event.inputs.ep }}"
          RESP1=$(curl -s "https://hihianimeapi.onrender.com/api/v1/episodes/a-${HID}")
          LINK_EP=$(echo "$RESP1" | jq -r ".data[] | select(.episodeNumber == ($EP|tonumber)) | .id")
          RESP2=$(curl -s "https://hihianimeapi.onrender.com/api/v1/stream?type=sub&server=hd-2&id=${LINK_EP}")
          LINK_DL=$(echo "$RESP2" | jq -r '.data.link.file')
          LINK_SUB=$(echo "$RESP2" | jq -r '.data.tracks[]? | select(.label == "English") | .file' | head -n 1)
          if [ -z "$LINK_SUB" ] || [ "$LINK_SUB" == "null" ]; then
            LINK_SUB=$(echo "$RESP2" | jq -r '.data.tracks[0].file')
          fi
          echo "LINK_DL=$LINK_DL" >> $GITHUB_ENV
          echo "LINK_SUB=$LINK_SUB" >> $GITHUB_ENV

      - name: Download video and subtitle
        run: |
          ffmpeg -i "$LINK_DL" -c copy -bsf:a aac_adtstoasc "raw_video.mp4"
          curl -L "$LINK_SUB" -o "eng.vtt"

      - name: AI Contextual Translation & TTS
        env:
          GEMINI_API_KEY: ${{ github.event.inputs.key }}
        run: |
          python3 <<EOF
          import webvtt
          from genai import Client
          import os, asyncio, edge_tts, time, re

          # Khá»Ÿi táº¡o AI tháº¿ há»‡ má»›i
          client = Client(api_key=os.environ['GEMINI_API_KEY'])

          async def process():
              vtt = webvtt.read('eng.vtt')
              total = len(vtt)
              if not os.path.exists('chunks'): os.makedirs('chunks')

              batch_size = 30
              all_translated_texts = [None] * total

              print(f"ðŸš€ AI Ä‘ang dá»‹ch {total} cÃ¢u phong cÃ¡ch Anime Fantasy...")

              for i in range(0, total, batch_size):
                  batch = vtt[i:i+batch_size]
                  en_text = "\n".join([f"{idx+i}: {cap.text}" for idx, cap in enumerate(batch)])
                  
                  prompt = f"Dá»‹ch sang tiáº¿ng Viá»‡t phong cÃ¡ch Anime Fantasy (VÆ°Æ¡ng Quá»‘c, Ma VÆ°Æ¡ng). DÃ¹ng Ta-NgÆ°Æ¡i cho Ä‘á»‘i Ä‘áº§u, Anh-Em cho thÃ¢n máº­t. Giá»¯ tÃªn riÃªng viáº¿t hoa. Äá»‹nh dáº¡ng 'ID: Ná»™i dung'. KhÃ´ng giáº£i thÃ­ch.\n\n{en_text}"
                  
                  try:
                      response = client.models.generate_content(model="gemini-1.5-flash", contents=prompt)
                      lines = response.text.strip().split('\n')
                      for line in lines:
                          match = re.match(r'^(\d+):\s*(.*)', line)
                          if match:
                              idx = int(match.group(1))
                              content = match.group(2).replace('*', '').strip()
                              if idx < total: all_translated_texts[idx] = content
                  except Exception as e:
                      print(f"Lá»—i AI táº¡i batch {i}: {e}")
                  
                  print(f"Tiáº¿n Ä‘á»™ dá»‹ch: {min(i+batch_size, total)}/{total}")
                  time.sleep(1)

              vi_vtt = webvtt.WebVTT()
              for i, caption in enumerate(vtt):
                  text_vi = all_translated_texts[i]
                  if not text_vi or len(text_vi) < 1:
                      text_vi = "." # TrÃ¡nh lá»—i NoAudioReceived
                  
                  vi_vtt.captions.append(webvtt.Caption(caption.start, caption.end, text_vi))
                  
                  # TTS vá»›i xá»­ lÃ½ lá»—i
                  try:
                      chunk_path = f"chunks/c_{i}.mp3"
                      communicate = edge_tts.Communicate(text_vi, "vi-VN-HoaiMyNeural")
                      await communicate.save(chunk_path)
                  except Exception as e:
                      print(f"Cáº£nh bÃ¡o TTS cÃ¢u {i}: {e}")
                      # Táº¡o file tráº¯ng náº¿u lá»—i Ä‘á»ƒ FFmpeg khÃ´ng crash
                      os.system(f"ffmpeg -f lavfi -i anullsrc=r=24000:cl=mono -t 0.1 -q:a 9 {chunk_path} -y")

              vi_vtt.save('vi.vtt')

          asyncio.run(process())
          EOF

      - name: Build Unified Filter Script
        run: |
          python3 <<EOF
          import webvtt, os
          vtt = webvtt.read('vi.vtt')
          with open('master_filter.txt', 'w') as f:
              for i, cap in enumerate(vtt):
                  h, m, s = cap.start.replace(',', '.').split(':')
                  ms = int(float(h)*3600000 + float(m)*60000 + float(s)*1000)
                  f.write(f"[{i+1}:a]adelay={ms}|{ms}[a{i}];")
              
              labels = "".join([f"[a{i}]" for i in range(len(vtt))])
              f.write(f"{labels}amix=inputs={len(vtt)}:dropout_transition=0,volume=3.5[tts_only];")
              f.write(f"[0:a]volume=0.6[bg_music];[bg_music][tts_only]amix=inputs=2:duration=first[out_audio];")
              f.write(f"[0:v]subtitles=vi.vtt:force_style='FontSize=20,PrimaryColour=&H00FFFF&,Outline=1,Shadow=1'[out_video]")
          EOF

      - name: Final Render (Fixed 5s Segment)
        run: |
          NAME="${{ github.event.inputs.type }}-${{ github.event.inputs.slug }}-${{ github.event.inputs.ss }}-${{ github.event.inputs.ep }}"
          INPUTS="-i raw_video.mp4"
          for f in $(ls -v chunks/c_*.mp3); do INPUTS="$INPUTS -i $f"; done

          ffmpeg -y $INPUTS -filter_complex_script master_filter.txt \
            -map "[out_video]" -map "[out_audio]" \
            -c:v libx264 -preset superfast -crf 22 -g 120 -keyint_min 120 -sc_threshold 0 \
            -c:a aac -b:a 128k "final_video.mp4"

          mkdir -p output
          ffmpeg -i final_video.mp4 -c copy -f hls -hls_time 5 \
            -hls_segment_type fmp4 -hls_fmp4_init_filename "${NAME}-index.png" \
            -hls_segment_filename "output/${NAME}-index%d.png" "output/${NAME}.m3u8"
          cp vi.vtt output/

      - name: Deploy to Cloudflare Pages
        uses: cloudflare/pages-action@v1
        with:
          apiToken: ${{ github.event.inputs.token }}
          accountId: ${{ github.event.inputs.account }}
          projectName: ${{ github.event.inputs.page }}
          directory: ./output
          branch: ${{ github.event.inputs.type }}-${{ github.event.inputs.slug }}-${{ github.event.inputs.ss }}-${{ github.event.inputs.ep }}
