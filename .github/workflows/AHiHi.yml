name: AHiHi to CF (Anime Style VNRub)

on:
  workflow_dispatch:
    inputs:
      type: { description: "Type", required: true }
      slug: { description: "Slug", required: true }
      ss: { description: "Season", required: true }
      ep: { description: "Ep", required: true }
      hid: { description: "Hid", required: true }
      token: { description: 'Token', required: true }
      page: { description: 'Page', required: true }
      account: { description: 'AID', required: true }

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Environment
        run: |
          sudo apt update
          sudo apt install -y ffmpeg curl jq python3 python3-pip
          pip3 install edge-tts deep-translator webvtt-py

      - name: Get download and subtitle link
        id: getlink
        run: |
          HID="${{ github.event.inputs.hid }}"
          EP="${{ github.event.inputs.ep }}"
          RESP1=$(curl -s "https://hihianimeapi.onrender.com/api/v1/episodes/a-${HID}")
          LINK_EP=$(echo "$RESP1" | jq -r ".data[] | select(.episodeNumber == ($EP|tonumber)) | .id")
          RESP2=$(curl -s "https://hihianimeapi.onrender.com/api/v1/stream?type=sub&server=hd-2&id=${LINK_EP}")
          LINK_DL=$(echo "$RESP2" | jq -r '.data.link.file')
          LINK_SUB=$(echo "$RESP2" | jq -r '.data.tracks[]? | select(.label == "English") | .file' | head -n 1)
          if [ -z "$LINK_SUB" ] || [ "$LINK_SUB" == "null" ]; then
            LINK_SUB=$(echo "$RESP2" | jq -r '.data.tracks[0].file')
          fi
          echo "LINK_DL=$LINK_DL" >> $GITHUB_ENV
          echo "LINK_SUB=$LINK_SUB" >> $GITHUB_ENV

      - name: Download video and subtitle
        run: |
          ffmpeg -i "$LINK_DL" -c copy -bsf:a aac_adtstoasc "raw_video.mp4"
          curl -L "$LINK_SUB" -o "eng.vtt"

      - name: Anime Style Translation and TTS
        run: |
          python3 <<EOF
          import webvtt
          from deep_translator import GoogleTranslator
          import asyncio
          import edge_tts
          import os
          import re

          # Tá»ª ÄIá»‚N ANIME FANTASY
          ANIME_DICT = {
              r"\bDemon King\b": "Ma VÆ°Æ¡ng",
              r"\bDemon Lord\b": "ChÃºa Tá»ƒ Quá»·",
              r"\bGod\b": "ThÆ°á»£ng Äáº¿",
              r"\bGoddess\b": "Ná»¯ Tháº§n",
              r"\bHero\b": "Anh HÃ¹ng",
              r"\bWorld\b": "VÆ°Æ¡ng Quá»‘c",
              r"\bKingdom\b": "VÆ°Æ¡ng Quá»‘c",
              r"\bPrincess\b": "CÃ´ng ChÃºa",
              r"\bPrince\b": "HoÃ ng Tá»­",
              r"\bHoly Sword\b": "ThÃ¡nh Kiáº¿m",
              r"\bMagic\b": "Ma PhÃ¡p",
              r"\bMaster\b": "SÆ° Phá»¥",
              r"\bSlave\b": "NÃ´ Lá»‡",
              r"\bVillage\b": "NgÃ´i LÃ ng",
              r"\bMonster\b": "QuÃ¡i Váº­t",
              # Äáº¡i tá»« nhÃ¢n xÆ°ng
              r"\bI am\b": "Ta lÃ ",
              r"\bI'm\b": "Ta lÃ ",
              r"\bI\b": "Ta",
              r"\bYou\b": "NgÆ°Æ¡i",
              r"\byou\b": "ngÆ°Æ¡i",
              r"\bMy\b": "Cá»§a ta",
              r"\bMe\b": "Ta",
          }

          def anime_refine(text):
              for pattern, replacement in ANIME_DICT.items():
                  text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
              return text

          async def process():
              translator = GoogleTranslator(source='en', target='vi')
              vtt = webvtt.read('eng.vtt')
              vi_vtt = webvtt.WebVTT()
              if not os.path.exists('chunks'): os.makedirs('chunks')
              
              total = len(vtt)
              print(f"ðŸš€ Báº¯t Ä‘áº§u dá»‹ch {total} cÃ¢u thoáº¡i phong cÃ¡ch Anime...")

              # Dá»‹ch theo cá»¥m Ä‘á»ƒ giá»¯ ngá»¯ cáº£nh (5 cÃ¢u má»™t láº§n)
              batch_size = 5
              for i in range(0, total, batch_size):
                  batch = vtt[i:i+batch_size]
                  raw_texts = [cap.text.replace("\n", " ") for cap in batch]
                  combined_en = " | ".join(raw_texts)
                  
                  try:
                      translated_vi = translator.translate(combined_en)
                      vi_lines = translated_vi.split(" | ")
                  except:
                      vi_lines = [translator.translate(t) for t in raw_texts]

                  for j, caption in enumerate(batch):
                      idx = i + j
                      text_vi = vi_lines[j] if j < len(vi_lines) else ""
                      # Ãp dá»¥ng tá»« Ä‘iá»ƒn Anime
                      text_vi = anime_refine(text_vi)
                      
                      # Hiá»ƒn thá»‹ tiáº¿n Ä‘á»™
                      print(f"[{round((idx+1)/total*100, 1)}%] {caption.start} -> {text_vi}")
                      
                      vi_vtt.captions.append(webvtt.Caption(caption.start, caption.end, text_vi))
                      
                      # Táº¡o Audio
                      chunk_path = f"chunks/c_{idx}.mp3"
                      communicate = edge_tts.Communicate(text_vi, "vi-VN-HoaiMyNeural")
                      await communicate.save(chunk_path)

              vi_vtt.save('vi.vtt')

          asyncio.run(process())
          EOF

      - name: Build Audio Filter Script
        run: |
          python3 <<EOF
          import webvtt
          vtt = webvtt.read('vi.vtt')
          with open('filter_script.txt', 'w') as f:
              filter_parts = []
              for i, cap in enumerate(vtt):
                  # Chuyá»ƒn timestamp sang milisec
                  h, m, s = cap.start.replace(',', '.').split(':')
                  ms = int(float(h)*3600000 + float(m)*60000 + float(s)*1000)
                  filter_parts.append(f"[{i+1}:a]adelay={ms}|{ms}[a{i}];")
              
              f.write("".join(filter_parts))
              mix_labels = "".join([f"[a{i}]" for i in range(len(vtt))])
              f.write(f"{mix_labels}amix=inputs={len(vtt)}:dropout_transition=0,volume=3.5[tts];")
          EOF

      - name: Final Render (Hardsub + Audio Mix + 5s Keyframe)
        run: |
          NAME="${{ github.event.inputs.type }}-${{ github.event.inputs.slug }}-${{ github.event.inputs.ss }}-${{ github.event.inputs.ep }}"
          
          # Chuáº©n bá»‹ danh sÃ¡ch input
          INPUTS="-i raw_video.mp4"
          for f in $(ls -v chunks/c_*.mp3); do
            INPUTS="$INPUTS -i $f"
          done

          # Encode Video:
          # - filter_complex_script: náº¡p filter tá»« file Ä‘á»ƒ trÃ¡nh lá»—i dÃ²ng lá»‡nh quÃ¡ dÃ i
          # - g 120: Ã©p keyframe má»—i 5 giÃ¢y (cho video 24fps)
          ffmpeg -y $INPUTS -filter_complex_script filter_script.txt \
            -filter_complex "[0:a]volume=0.6[bg];[bg][tts]amix=inputs=2:duration=first[outa];[0:v]subtitles=vi.vtt:force_style='FontSize=20,PrimaryColour=&H00FFFF&,Outline=1,Shadow=1'[outv]" \
            -map "[outv]" -map "[outa]" \
            -c:v libx264 -preset superfast -crf 22 \
            -g 120 -keyint_min 120 -sc_threshold 0 \
            -c:a aac -b:a 128k "final_video.mp4"

          # TÃ¡ch HLS thÃ nh cÃ¡c Ä‘oáº¡n PNG dÃ i Ä‘Ãºng 5s
          mkdir -p output
          ffmpeg -i final_video.mp4 -c copy \
            -f hls -hls_time 5 -hls_playlist_type static \
            -hls_segment_type fmp4 -hls_fmp4_init_filename "${NAME}-index.png" \
            -hls_segment_filename "output/${NAME}-index%d.png" "output/${NAME}.m3u8"
          
          cp vi.vtt output/

      - name: Deploy to Cloudflare Pages
        uses: cloudflare/pages-action@v1
        with:
          apiToken: ${{ github.event.inputs.token }}
          accountId: ${{ github.event.inputs.account }}
          projectName: ${{ github.event.inputs.page }}
          directory: ./output
          branch: ${{ github.event.inputs.type }}-${{ github.event.inputs.slug }}-${{ github.event.inputs.ss }}-${{ github.event.inputs.ep }}
