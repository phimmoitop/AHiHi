name: AHiHi to CF (AI Anime Master)

on:
  workflow_dispatch:
    inputs:
      type: { description: "Type", required: true }
      slug: { description: "Slug", required: true }
      ss: { description: "Season", required: true }
      ep: { description: "Ep", required: true }
      hid: { description: "Hid", required: true }
      token: { description: 'Token', required: true }
      page: { description: 'Page', required: true }
      account: { description: 'AID', required: true }
      key: { description: 'Gemini API Key', required: true }

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Environment
        run: |
          sudo apt update
          sudo apt install -y ffmpeg curl jq python3 python3-pip
          python3 -m pip install --upgrade pip
          python3 -m pip install edge-tts webvtt-py google-genai

      - name: Get download and subtitle link
        id: getlink
        run: |
          HID="${{ github.event.inputs.hid }}"
          EP="${{ github.event.inputs.ep }}"
          RESP1=$(curl -s "https://hihianimeapi.onrender.com/api/v1/episodes/a-${HID}")
          LINK_EP=$(echo "$RESP1" | jq -r ".data[] | select(.episodeNumber == ($EP|tonumber)) | .id")
          RESP2=$(curl -s "https://hihianimeapi.onrender.com/api/v1/stream?type=sub&server=hd-2&id=${LINK_EP}")
          LINK_DL=$(echo "$RESP2" | jq -r '.data.link.file')
          LINK_SUB=$(echo "$RESP2" | jq -r '.data.tracks[]? | select(.label == "English") | .file' | head -n 1)
          if [ -z "$LINK_SUB" ] || [ "$LINK_SUB" == "null" ]; then
            LINK_SUB=$(echo "$RESP2" | jq -r '.data.tracks[0].file')
          fi
          echo "LINK_DL=$LINK_DL" >> $GITHUB_ENV
          echo "LINK_SUB=$LINK_SUB" >> $GITHUB_ENV

      - name: Download video and subtitle
        run: |
          ffmpeg -i "$LINK_DL" -c copy -bsf:a aac_adtstoasc "raw_video.mp4"
          curl -L "$LINK_SUB" -o "eng.vtt"

      - name: AI Contextual Translation & TTS
        env:
          GEMINI_API_KEY: ${{ github.event.inputs.key }}
        run: |
          python3 <<EOF
          import webvtt
          from google import genai
          import os, asyncio, edge_tts, time, re, subprocess

          client = genai.Client(api_key=os.environ['GEMINI_API_KEY'])

          def safe_vi_fallback(en_text: str) -> str:
              """
              Fallback cá»±c an toÃ n:
              - Giá»¯ sub (dÃ¹ khÃ´ng hay)
              - KhÃ´ng Ä‘á»ƒ trá»‘ng
              """
              return en_text.strip()

          async def process():
              vtt = webvtt.read('eng.vtt')
              total = len(vtt)

              if not os.path.exists('chunks'):
                  os.makedirs('chunks')

              batch_size = 10  # giáº£m ná»¯a cho Gemini á»•n Ä‘á»‹nh
              all_translated_texts = [None] * total

              print(f"ðŸš€ AI Ä‘ang dá»‹ch {total} cÃ¢u subtitle...")

              for i in range(0, total, batch_size):
                  batch = vtt[i:i+batch_size]

                  en_text = "\n".join(
                      f"{i+idx}: {cap.text.replace(chr(10),' ').strip()}"
                      for idx, cap in enumerate(batch)
                  )

                  prompt = f"""
          Dá»‹ch sang tiáº¿ng Viá»‡t.
          Báº®T BUá»˜C giá»¯ nguyÃªn ID.
          Má»—i dÃ²ng Ä‘Ãºng 1 dÃ²ng.
          Format: ID: Ná»™i dung
          KHÃ”NG markdown, KHÃ”NG giáº£i thÃ­ch.

          {en_text}
          """

                  try:
                      response = client.models.generate_content(
                          model="gemini-1.5-flash",
                          contents=prompt
                      )

                      lines = response.text.splitlines()
                      for line in lines:
                          m = re.match(r'^(\d+):\s*(.+)', line.strip())
                          if not m:
                              continue
                          idx = int(m.group(1))
                          text = m.group(2).replace('*', '').strip()
                          if 0 <= idx < total and text:
                              all_translated_texts[idx] = text

                  except Exception as e:
                      print(f"âŒ Gemini lá»—i batch {i}: {e}")

                  time.sleep(1)

              vi_vtt = webvtt.WebVTT()

              for i, cap in enumerate(vtt):
                  text_vi = all_translated_texts[i]

                  # âœ… Äáº¢M Báº¢O SUB LUÃ”N CÃ“
                  if not text_vi or len(text_vi.strip()) < 2:
                      text_vi = safe_vi_fallback(cap.text)

                  vi_vtt.captions.append(
                      webvtt.Caption(cap.start, cap.end, text_vi)
                  )

                  chunk_path = f"chunks/c_{i}.mp3"

                  # âœ… CHá»ˆ TTS KHI CHáº®C CHáº®N LÃ€ TIáº¾NG VIá»†T
                  if all_translated_texts[i]:
                      try:
                          communicate = edge_tts.Communicate(
                              text_vi,
                              voice="vi-VN-HoaiMyNeural"
                          )
                          await communicate.save(chunk_path)
                      except:
                          subprocess.run(
                              ["ffmpeg", "-y", "-f", "lavfi", "-i",
                               "anullsrc=r=24000:cl=mono", "-t", "0.1", chunk_path],
                              stdout=subprocess.DEVNULL,
                              stderr=subprocess.DEVNULL
                          )
                  else:
                      # AI fail â†’ im láº·ng
                      subprocess.run(
                          ["ffmpeg", "-y", "-f", "lavfi", "-i",
                           "anullsrc=r=24000:cl=mono", "-t", "0.1", chunk_path],
                          stdout=subprocess.DEVNULL,
                          stderr=subprocess.DEVNULL
                      )

              vi_vtt.save('vi.vtt')
              print("âœ… HoÃ n táº¥t dá»‹ch + táº¡o sub Viá»‡t + audio")

          asyncio.run(process())
          EOF



      - name: Build Unified Filter Script
        run: |
          python3 <<EOF
          import webvtt
          vtt = webvtt.read('vi.vtt')
          with open('master_filter.txt', 'w') as f:
              # Sá»­a cÃº phÃ¡p: [input_index:a] khÃ´ng cÃ³ dáº¥u cÃ¡ch trÆ°á»›c adelay
              for i, cap in enumerate(vtt):
                  h, m, s = cap.start.replace(',', '.').split(':')
                  ms = int(float(h)*3600000 + float(m)*60000 + float(s)*1000)
                  f.write(f"[{i+1}:a]adelay={ms}|{ms}[a{i}];")
              
              # Mix audio theo batch Ä‘á»ƒ trÃ¡nh giá»›i háº¡n 32 inputs cá»§a amix
              batch_size = 20
              labels = [f"[a{i}]" for i in range(len(vtt))]
              mix_labels = []
              for i in range(0, len(labels), batch_size):
                  batch = labels[i:i+batch_size]
                  f.write(f"{''.join(batch)}amix=inputs={len(batch)}:dropout_transition=0[m{i}];")
                  mix_labels.append(f"[m{i}]")
              
              # Trá»™n cÃ¡c báº£n mix trung gian láº¡i
              f.write(f"{''.join(mix_labels)}amix=inputs={len(mix_labels)}:dropout_transition=0,volume=3.5[tts_only];")
              f.write(f"[0:a]volume=0.6[bg_music];[bg_music][tts_only]amix=inputs=2:duration=first[out_audio];")
              # ThÃªm nhÃ¡y Ä‘Æ¡n cho vi.vtt
              f.write(f"[0:v]subtitles='vi.vtt':force_style='FontSize=20,PrimaryColour=&H00FFFF&,Outline=1,Shadow=1'[out_video]")
          EOF

      - name: Final Render & Accurate HLS
        run: |
          NAME="${{ github.event.inputs.type }}-${{ github.event.inputs.slug }}-${{ github.event.inputs.ss }}-${{ github.event.inputs.ep }}"
          
          INPUTS="-i raw_video.mp4"
          for f in $(ls -v chunks/c_*.mp3); do INPUTS="$INPUTS -i $f"; done

          ffmpeg -y $INPUTS -filter_complex_script master_filter.txt \
            -map "[out_video]" -map "[out_audio]" \
            -c:v libx264 -preset superfast -crf 22 \
            -force_key_frames "expr:gte(t,n_forced*5)" \
            -c:a aac -b:a 128k "final_video.mp4"

          mkdir -p output
          ffmpeg -i final_video.mp4 -c copy \
            -f hls \
            -hls_time 5 \
            -hls_list_size 0 \
            -hls_playlist_type vod \
            -hls_segment_type fmp4 \
            -hls_fmp4_init_filename "${NAME}-index.png" \
            -hls_segment_filename "output/${NAME}-index%d.png" \
            "output/${NAME}.m3u8"
          
          cp vi.vtt output/

      - name: Deploy to Cloudflare Pages
        uses: cloudflare/pages-action@v1
        with:
          apiToken: ${{ github.event.inputs.token }}
          accountId: ${{ github.event.inputs.account }}
          projectName: ${{ github.event.inputs.page }}
          directory: ./output
          branch: ${{ github.event.inputs.type }}-${{ github.event.inputs.slug }}-${{ github.event.inputs.ss }}-${{ github.event.inputs.ep }}
