name: AHiHi to CF (AI Dubbing Master - Full)

on:
  workflow_dispatch:
    inputs:
      type: { description: "Type", required: true }
      slug: { description: "Slug", required: true }
      ss: { description: "Season", required: true }
      ep: { description: "Ep", required: true }
      hid: { description: "Hid", required: true }
      token: { description: 'Token', required: true }
      page: { description: 'Page', required: true }
      account: { description: 'AID', required: true }
      key: { description: 'Gemini API Key', required: true }

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Environment
        run: |
          sudo apt update
          sudo apt install -y ffmpeg curl jq python3 python3-pip
          python3 -m pip install --upgrade pip
          python3 -m pip install webvtt-py requests edge-tts

      - name: Get download and subtitle link
        id: getlink
        run: |
          HID="${{ github.event.inputs.hid }}"
          EP="${{ github.event.inputs.ep }}"
          RESP1=$(curl -s "https://hihianimeapi.onrender.com/api/v1/episodes/a-${HID}")
          LINK_EP=$(echo "$RESP1" | jq -r ".data[] | select(.episodeNumber == ($EP|tonumber)) | .id")
          RESP2=$(curl -s "https://hihianimeapi.onrender.com/api/v1/stream?type=sub&server=hd-2&id=${LINK_EP}")
          LINK_DL=$(echo "$RESP2" | jq -r '.data.link.file')
          LINK_SUB=$(echo "$RESP2" | jq -r '.data.tracks[]? | select(.label == "English") | .file' | head -n 1)
          if [ -z "$LINK_SUB" ] || [ "$LINK_SUB" == "null" ]; then
            LINK_SUB=$(echo "$RESP2" | jq -r '.data.tracks[0].file')
          fi
          echo "LINK_DL=$LINK_DL" >> $GITHUB_ENV
          echo "LINK_SUB=$LINK_SUB" >> $GITHUB_ENV

      - name: Download video and subtitle
        run: |
          ffmpeg -i "$LINK_DL" -c copy -bsf:a aac_adtstoasc "raw_video.mp4"
          curl -L "$LINK_SUB" -o "eng.vtt"

      - name: AI Translation & TTS Generation
        env:
          GEMINI_API_KEY: ${{ github.event.inputs.key }}
        run: |
          python3 <<'EOF'
          import webvtt
          import os, time, re, requests, json, asyncio, edge_tts, subprocess

          API_KEY = os.environ['GEMINI_API_KEY']

          def get_model():
              url = f"https://generativelanguage.googleapis.com/v1/models?key={API_KEY}"
              try:
                  res = requests.get(url).json()
                  available = [m['name'] for m in res.get('models', []) if 'generateContent' in m['supportedGenerationMethods']]
                  # Æ¯u tiÃªn cÃ¡c model báº¡n Ä‘ang cÃ³ theo thá»© tá»± máº¡nh/má»›i nháº¥t
                  for target in ['gemini-2.5-flash', 'gemini-2.0-flash', 'gemini-1.5-flash']:
                      for name in available:
                          if target in name: return name
                  return available[0]
              except: return None

          def translate_batch(model_name, prompt_text):
              version = "v1beta" # CÃ¡c dÃ²ng 2.0/2.5 thÆ°á»ng dÃ¹ng v1beta
              url = f"https://generativelanguage.googleapis.com/{version}/{model_name}:generateContent?key={API_KEY}"
              payload = {"contents": [{"parts": [{"text": prompt_text}]}], "generationConfig": {"temperature": 0.2}}
              try:
                  res = requests.post(url, json=payload, timeout=60).json()
                  return res["candidates"][0]["content"]["parts"][0]["text"]
              except: return None

          async def generate_tts(text, output_path):
              try:
                  communicate = edge_tts.Communicate(text, "vi-VN-HoaiMyNeural")
                  await communicate.save(output_path)
              except:
                  # Táº¡o file láº·ng náº¿u lá»—i
                  subprocess.run(["ffmpeg", "-y", "-f", "lavfi", "-i", "anullsrc=r=24000:cl=mono", "-t", "0.1", output_path], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

          async def main():
              chosen_model = get_model()
              print(f"ðŸŽ¯ Sá»­ dá»¥ng Model: {chosen_model}")
              vtt = webvtt.read('eng.vtt')
              total = len(vtt)
              batch_size = 30
              all_vi = [None] * total
              
              if not os.path.exists('chunks'): os.makedirs('chunks')

              # 1. Dá»ŠCH
              for i in range(0, total, batch_size):
                  batch = vtt[i:i+batch_size]
                  prompt = "Dá»‹ch sang tiáº¿ng Viá»‡t (Anime style). Giá»¯ Ä‘á»‹nh dáº¡ng ID: Ná»™i dung. KhÃ´ng giáº£i thÃ­ch.\n\n"
                  prompt += "\n".join([f"{i+idx}: {cap.text.replace(chr(10), ' ')}" for idx, cap in enumerate(batch)])
                  
                  res_text = translate_batch(chosen_model, prompt)
                  if res_text:
                      for line in res_text.replace('```','').splitlines():
                          m = re.match(r'^(\d+):\s*(.+)', line.strip())
                          if m:
                              idx, txt = int(m.group(1)), m.group(2).strip()
                              if 0 <= idx < total: all_vi[idx] = txt
                  print(f"âœ… ÄÃ£ dá»‹ch batch {i}")
                  time.sleep(1)

              # 2. Táº O TTS & LÆ¯U VTT
              vi_vtt = webvtt.WebVTT()
              print("ðŸŽ™ï¸ Äang táº¡o giá»ng nÃ³i AI...")
              tasks = []
              for i, cap in enumerate(vtt):
                  txt_vi = all_vi[i] if all_vi[i] else cap.text
                  vi_vtt.captions.append(webvtt.Caption(cap.start, cap.end, txt_vi))
                  tasks.append(generate_tts(txt_vi, f"chunks/c_{i}.mp3"))
              
              await asyncio.gather(*tasks)
              vi_vtt.save('vi.vtt')
              print("âœ¨ HoÃ n táº¥t dá»‹ch vÃ  táº¡o Audio chunks")

          asyncio.run(main())
          EOF

      - name: Build Audio Filter & Render
        run: |
          python3 <<EOF
          import webvtt, os
          vtt = webvtt.read('vi.vtt')
          with open('master_filter.txt', 'w') as f:
              # Delay tá»«ng Ä‘oáº¡n audio theo thá»i gian sub
              for i, cap in enumerate(vtt):
                  h, m, s = cap.start.replace(',', '.').split(':')
                  ms = int(float(h)*3600000 + float(m)*60000 + float(s)*1000)
                  f.write(f"[{i+1}:a]adelay={ms}|{ms}[a{i}];")
              
              # Trá»™n audio (batch 20 Ä‘á»ƒ trÃ¡nh giá»›i háº¡n amix)
              batch_size = 20
              labels = [f"[a{i}]" for i in range(len(vtt))]
              mix_labels = []
              for i in range(0, len(labels), batch_size):
                  batch = labels[i:i+batch_size]
                  f.write(f"{''.join(batch)}amix=inputs={len(batch)}:dropout_transition=0[m{i}];")
                  mix_labels.append(f"[m{i}]")
              
              # Mix TTS tá»•ng há»£p vá»›i nháº¡c ná»n (Duck nháº¡c ná»n xuá»‘ng 0.4)
              f.write(f"{''.join(mix_labels)}amix=inputs={len(mix_labels)}:dropout_transition=0,volume=3.0[tts];")
              f.write(f"[0:a]volume=0.4[bg];[bg][tts]amix=inputs=2:duration=first[out_a];")
              # Hardsub tiáº¿ng Viá»‡t
              f.write(f"[0:v]subtitles='vi.vtt':force_style='FontSize=20,PrimaryColour=&H00FFFF&,Outline=1,Shadow=1'[out_v]")
          EOF

          # Tá»•ng há»£p video
          INPUTS="-i raw_video.mp4"
          for f in $(ls -v chunks/c_*.mp3); do INPUTS="$INPUTS -i $f"; done
          
          ffmpeg -y $INPUTS -filter_complex_script master_filter.txt \
            -map "[out_v]" -map "[out_a]" \
            -c:v libx264 -preset superfast -crf 23 \
            -c:a aac -b:a 128k "final_video.mp4"

      - name: Packaging HLS
        run: |
          NAME="${{ github.event.inputs.type }}-${{ github.event.inputs.slug }}-${{ github.event.inputs.ss }}-${{ github.event.inputs.ep }}"
          mkdir -p output
          ffmpeg -i final_video.mp4 -c copy \
            -f hls -hls_time 6 -hls_list_size 0 \
            -hls_segment_type fmp4 \
            -hls_fmp4_init_filename "${NAME}-index.png" \
            -hls_segment_filename "output/${NAME}-index%d.png" \
            "output/${NAME}.m3u8"
          cp vi.vtt output/

      - name: Deploy to Cloudflare Pages
        uses: cloudflare/pages-action@v1
        with:
          apiToken: ${{ github.event.inputs.token }}
          accountId: ${{ github.event.inputs.account }}
          projectName: ${{ github.event.inputs.page }}
          directory: ./output
          branch: ${{ github.event.inputs.type }}-${{ github.event.inputs.slug }}-${{ github.event.inputs.ss }}-${{ github.event.inputs.ep }}
